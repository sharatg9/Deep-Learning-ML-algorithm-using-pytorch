{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3zc0q5GcE4dfDAFMH0/XM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharatg9/Deep-Learning-ML-algorithm-using-pytorch/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB8GTHOJYy_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        \n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "     \n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        \n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "        \n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "        \n",
        "        # Convolution 2 \n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "        \n",
        "        # Max pool 2 \n",
        "        out = self.maxpool2(out)\n",
        "        \n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "model = CNNModel()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCd3aEIUie0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullModel(nn.Module):\n",
        "  \"\"\"\n",
        "  Distribute the loss on multi-gpu to reduce \n",
        "  the memory cost in the main gpu.\n",
        "  You can check the following discussion.\n",
        "  https://discuss.pytorch.org/t/dataparallel-imbalanced-memory-usage/22551/21\n",
        "  \"\"\"\n",
        "  def __init__(self, model, loss):\n",
        "    super(FullModel, self).__init__()\n",
        "    self.model = model\n",
        "    self.loss = loss\n",
        "\n",
        "  def forward(self, inputs, labels):\n",
        "    outputs = self.model(inputs)\n",
        "    loss = self.loss(outputs, labels)\n",
        "    return torch.unsqueeze(loss,0), outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be3ETvxng-92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e86e3058-e659-42cc-bc63-8ef2af726ec4"
      },
      "source": [
        "model = FullModel(model, criterion)\n",
        "\n",
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FullModel(\n",
            "  (model): CNNModel(\n",
            "    (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (relu1): ReLU()\n",
            "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (relu2): ReLU()\n",
            "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            "  (loss): CrossEntropyLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1zLEvjpe7tM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "793980cd-08f4-4193-8ba0-aa19f2e81af6"
      },
      "source": [
        "for i, (images, labels) in enumerate(train_loader):\n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "            labels = Variable(labels)\n",
        "        \n",
        "        if i == 2:\n",
        "          image_2 = images\n",
        "\n",
        "        # Forward pass only to get logits/output\n",
        "        # HRNET \n",
        "        outputs = model(images, labels) \n",
        "        \n",
        "        #or others \n",
        "        output2 = model(images)\n",
        "        loss = criterion(output2, labels)\n",
        "        \n",
        "        if i == 40:\n",
        "          print(images)\n",
        "          print(labels)\n",
        "          print(outputs)\n",
        "          #output2 = model(image_2)\n",
        "          #print(\"lets rock\", output2)\n",
        "          break\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
            "tensor([1, 2, 8, 8, 7, 8, 4, 0, 1, 4, 2, 6, 1, 8, 3, 1, 4, 8, 3, 8, 8, 4, 0, 7,\n",
            "        6, 8, 9, 9, 2, 3, 1, 8, 9, 6, 3, 1, 8, 3, 4, 6, 5, 5, 2, 8, 8, 1, 4, 9,\n",
            "        2, 1, 6, 4, 7, 3, 2, 9, 8, 8, 8, 7, 3, 7, 1, 0, 4, 3, 8, 1, 7, 6, 1, 1,\n",
            "        1, 4, 4, 2, 9, 2, 1, 4, 0, 1, 0, 4, 5, 6, 1, 0, 7, 2, 5, 1, 3, 5, 2, 4,\n",
            "        7, 7, 3, 6], device='cuda:0')\n",
            "(tensor([2.3295], device='cuda:0', grad_fn=<UnsqueezeBackward0>), tensor([[-7.8431e-02, -9.6055e-02,  1.4319e-02, -4.8211e-02, -3.4120e-02,\n",
            "         -8.3306e-02,  4.8437e-02,  3.0810e-02, -2.0516e-01, -5.7602e-02],\n",
            "        [-7.4116e-02, -1.2552e-01,  3.6587e-02, -5.6233e-02, -5.2460e-03,\n",
            "         -9.6926e-02,  5.0946e-02,  2.8374e-02, -2.3986e-01, -4.9018e-02],\n",
            "        [-4.0893e-02, -2.0980e-01,  6.6535e-02, -3.9079e-02,  3.1111e-02,\n",
            "         -1.7661e-01,  5.0024e-02,  7.1395e-02, -2.3137e-01, -1.5830e-02],\n",
            "        [-9.2657e-02, -2.3120e-01,  5.1568e-02, -3.3878e-02, -1.6188e-02,\n",
            "         -1.5878e-01,  6.7212e-02,  4.5861e-02, -2.6570e-01, -6.9642e-02],\n",
            "        [-2.3712e-02, -1.6667e-01,  7.2773e-02, -7.9923e-02,  7.2430e-03,\n",
            "         -1.6472e-01,  2.5588e-02,  4.8838e-02, -2.1074e-01, -4.3537e-02],\n",
            "        [-6.7515e-02, -2.0727e-01,  5.1596e-02, -5.1344e-02, -1.1291e-02,\n",
            "         -9.8480e-02,  9.4035e-02,  4.9235e-02, -1.9585e-01, -1.0837e-01],\n",
            "        [-8.2688e-02, -2.4314e-01,  6.1908e-02, -8.6628e-02,  1.8703e-02,\n",
            "         -1.6094e-01,  7.6090e-02,  1.9509e-02, -1.9199e-01, -5.5938e-02],\n",
            "        [-4.5074e-02, -2.1345e-01,  2.2179e-02, -1.1771e-02,  3.7150e-02,\n",
            "         -2.1479e-01, -2.0417e-02, -4.1464e-02, -2.5611e-01,  2.5708e-02],\n",
            "        [-1.2328e-01, -2.2606e-01,  5.1487e-02, -6.5008e-02,  4.7636e-03,\n",
            "         -1.6775e-01,  4.0734e-02,  4.3828e-02, -2.1799e-01, -5.5804e-02],\n",
            "        [ 3.4023e-02, -2.2430e-01,  9.1620e-02, -1.1086e-01, -1.2970e-02,\n",
            "         -1.2087e-01,  1.1227e-01, -4.4629e-03, -2.3045e-01, -8.7447e-02],\n",
            "        [-1.8693e-02, -1.6066e-01,  1.5128e-02, -5.5285e-02,  4.3553e-02,\n",
            "         -9.8558e-02,  1.0597e-01,  4.2147e-03, -1.7706e-01, -4.5135e-02],\n",
            "        [-2.0599e-02, -1.6963e-01,  6.4278e-02, -5.5689e-02,  1.6741e-03,\n",
            "         -1.0344e-01,  4.8004e-02,  8.9282e-03, -1.6076e-01, -6.1351e-03],\n",
            "        [-8.8500e-02, -1.0866e-01,  1.8995e-02, -7.9773e-02, -1.5212e-02,\n",
            "         -1.0723e-01,  1.2388e-02,  4.4889e-02, -2.2904e-01, -5.9951e-02],\n",
            "        [-4.2772e-03, -1.7876e-01,  2.0802e-02, -3.8018e-02,  3.0802e-02,\n",
            "         -1.2172e-01,  1.2562e-01,  1.2808e-02, -1.6386e-01,  7.8193e-03],\n",
            "        [-5.6209e-02, -2.0183e-01,  2.4036e-02, -1.5406e-01,  1.9157e-02,\n",
            "         -1.8228e-01,  6.1532e-02, -1.8240e-02, -3.0343e-01, -1.9286e-02],\n",
            "        [-7.6396e-02, -2.2946e-01,  8.2603e-02, -6.5893e-02,  2.5415e-02,\n",
            "         -1.0440e-01,  4.7915e-02,  3.9708e-02, -1.6590e-01, -5.6541e-02],\n",
            "        [-2.2270e-03, -1.6039e-01,  7.4347e-02, -1.3658e-01, -4.1372e-02,\n",
            "         -1.5765e-01,  8.3938e-02,  1.7560e-02, -2.2355e-01, -5.9661e-02],\n",
            "        [-1.1004e-01, -2.2676e-01,  5.3348e-02, -1.8083e-02,  2.3499e-02,\n",
            "         -1.6915e-01,  5.4339e-02,  3.0704e-02, -2.4198e-01, -6.8348e-02],\n",
            "        [-9.6816e-02, -1.7115e-01,  7.0678e-02, -8.8090e-02,  3.6465e-02,\n",
            "         -1.5977e-01,  7.3694e-02,  8.7892e-02, -2.5165e-01,  7.2976e-03],\n",
            "        [-5.1012e-02, -1.6027e-01,  8.1607e-02, -1.7828e-02,  2.8249e-02,\n",
            "         -9.4570e-02,  4.2061e-02, -9.7076e-03, -2.3476e-01,  8.5916e-02],\n",
            "        [-9.6616e-02, -2.9630e-01,  2.6028e-02, -6.5932e-02,  9.3208e-03,\n",
            "         -2.3927e-01,  5.8449e-02, -8.1935e-03, -3.2714e-01, -3.5632e-02],\n",
            "        [ 2.5850e-02, -1.2178e-01,  3.0398e-02, -1.1482e-01, -3.0171e-02,\n",
            "         -1.5647e-01,  1.0589e-01,  3.3326e-02, -1.6697e-01, -7.0582e-02],\n",
            "        [-1.0701e-01, -1.5660e-01, -4.7982e-02, -6.7955e-02, -2.1955e-02,\n",
            "         -2.1050e-01,  5.8799e-02,  3.5399e-02, -2.4401e-01, -2.4822e-02],\n",
            "        [ 8.9568e-03, -1.1427e-01,  1.2894e-01, -4.4065e-02,  7.9799e-02,\n",
            "         -3.6757e-02,  2.5572e-02,  7.2723e-02, -9.9726e-02, -2.5512e-02],\n",
            "        [-2.8084e-02, -1.6193e-01, -3.4622e-02, -1.1396e-02, -3.1651e-02,\n",
            "         -4.1989e-02,  1.0498e-01, -9.1603e-03, -1.4437e-01, -4.3410e-02],\n",
            "        [-9.7450e-02, -1.2186e-01,  1.4339e-02, -3.3398e-02,  3.3284e-02,\n",
            "         -9.0744e-02,  3.2622e-02,  2.8220e-02, -2.3969e-01, -4.4084e-03],\n",
            "        [-5.5593e-03, -2.3776e-01,  1.0054e-01, -8.5720e-02,  6.8336e-02,\n",
            "         -1.7142e-01,  8.6157e-02,  3.9550e-02, -1.8319e-01, -4.2189e-03],\n",
            "        [-6.0002e-02, -1.5537e-01,  5.7220e-02, -6.3369e-02,  4.7371e-02,\n",
            "         -1.7232e-01,  2.5165e-02,  4.6499e-02, -2.4092e-01,  1.3031e-02],\n",
            "        [-5.5162e-02, -1.8735e-01,  8.1328e-02, -1.1956e-01,  2.2431e-02,\n",
            "         -1.0973e-01,  1.0111e-01,  2.1704e-02, -1.8305e-01, -3.3860e-02],\n",
            "        [-5.1277e-02, -1.6780e-01,  5.4543e-02, -3.6015e-02,  2.5883e-02,\n",
            "         -1.6572e-01,  5.3574e-02,  5.2360e-02, -2.8116e-01, -4.2119e-02],\n",
            "        [-9.4160e-02, -1.6262e-01,  6.9177e-02, -8.3237e-02,  5.2677e-03,\n",
            "         -1.1225e-01,  3.0744e-02,  4.1228e-02, -2.0487e-01, -5.1944e-02],\n",
            "        [-2.4007e-02, -1.4680e-01,  5.6617e-02, -2.3334e-02,  1.9991e-02,\n",
            "         -1.0725e-01,  3.9914e-03,  1.2369e-02, -1.7968e-01, -9.8927e-03],\n",
            "        [-1.8376e-02, -1.9082e-01,  1.0111e-01, -7.3029e-02,  3.5671e-02,\n",
            "         -1.4915e-01,  3.2163e-02,  2.2167e-02, -2.1236e-01, -9.7696e-03],\n",
            "        [-5.5110e-02, -1.3626e-01, -1.0756e-02,  9.4564e-03, -8.4807e-03,\n",
            "         -8.4103e-02,  9.9603e-02, -2.0637e-02, -2.2799e-01, -9.5108e-03],\n",
            "        [-5.1981e-02, -1.9924e-01,  1.1990e-02, -8.4536e-02,  1.8762e-02,\n",
            "         -1.5001e-01,  6.1788e-02, -8.7692e-03, -2.0547e-01,  2.4370e-02],\n",
            "        [-8.2295e-02, -5.9037e-02, -9.1634e-04, -6.8949e-02, -7.8089e-03,\n",
            "         -8.3948e-02,  4.1956e-02,  3.4473e-02, -2.0127e-01, -4.1987e-02],\n",
            "        [ 7.9445e-03, -1.6628e-01,  4.5484e-02, -1.0391e-01,  8.4725e-03,\n",
            "         -1.4209e-01,  9.0122e-02,  7.9254e-03, -1.8205e-01, -2.6758e-02],\n",
            "        [-4.5159e-02, -9.0837e-02,  5.8782e-02, -4.8124e-02, -5.7767e-02,\n",
            "         -1.3285e-01,  8.2574e-02,  1.8100e-01, -1.8149e-01, -1.0003e-01],\n",
            "        [ 7.2613e-03, -2.0976e-01,  9.1694e-02, -1.2940e-01, -1.4208e-02,\n",
            "         -1.3906e-01,  1.9875e-01,  3.4007e-02, -1.4811e-01, -1.1796e-01],\n",
            "        [-1.1545e-02, -1.9457e-01,  2.9548e-02, -2.7717e-02,  3.0001e-02,\n",
            "         -1.1822e-01,  6.7487e-02,  4.6702e-03, -2.2738e-01,  7.9457e-02],\n",
            "        [-9.6590e-02, -2.2749e-01,  6.3178e-02, -6.4359e-02, -9.8983e-03,\n",
            "         -2.0851e-01,  2.6180e-02,  2.0725e-02, -2.5643e-01,  3.8733e-02],\n",
            "        [-7.0446e-02, -7.4787e-02,  3.6399e-02, -7.9967e-02,  2.3321e-02,\n",
            "         -1.0494e-01,  3.8084e-02,  4.0825e-02, -1.8035e-01, -2.2626e-02],\n",
            "        [-7.0483e-02, -9.4395e-02, -1.9523e-03, -9.0424e-02, -2.9899e-02,\n",
            "         -9.1927e-02,  1.1416e-01,  6.9571e-02, -2.1072e-01, -1.8317e-02],\n",
            "        [-1.0509e-01, -2.4423e-01,  6.7001e-02, -7.2735e-02, -5.3270e-03,\n",
            "         -1.3814e-01,  3.2831e-02,  4.4365e-02, -2.5232e-01, -1.3951e-02],\n",
            "        [-2.5127e-02, -1.9845e-01,  4.0625e-02, -2.3139e-02,  5.3954e-02,\n",
            "         -1.4935e-01,  5.1354e-02, -9.4369e-03, -2.2975e-01,  1.0771e-01],\n",
            "        [-1.2526e-01, -1.5738e-01,  7.2913e-02, -7.6798e-02,  5.0263e-03,\n",
            "         -9.3151e-02,  4.5267e-02,  7.5862e-02, -2.3402e-01, -8.1450e-02],\n",
            "        [-3.0033e-02, -1.8741e-01, -1.1385e-02, -3.2114e-02,  1.4053e-02,\n",
            "         -1.4541e-01,  3.7777e-02,  2.4327e-02, -2.0466e-01,  6.0804e-02],\n",
            "        [-8.9810e-02, -2.2849e-01,  5.9150e-02, -7.6338e-02,  3.9020e-02,\n",
            "         -1.6869e-01, -7.3906e-04,  4.7081e-02, -1.9466e-01,  3.9455e-02],\n",
            "        [-4.7615e-02, -1.2800e-01, -2.3706e-02, -1.0268e-01, -5.6881e-02,\n",
            "         -1.1623e-01,  1.3457e-01,  5.8666e-02, -2.0346e-01, -5.6430e-02],\n",
            "        [-9.0621e-02, -1.2555e-01,  4.3145e-02, -6.5262e-02,  3.6754e-03,\n",
            "         -9.9055e-02,  4.8427e-02,  7.3348e-02, -2.3948e-01, -7.3580e-02],\n",
            "        [-8.8953e-02, -1.8447e-01,  5.4703e-02, -5.5300e-02, -9.2279e-03,\n",
            "         -1.4479e-01,  1.0595e-01,  4.1436e-02, -2.7455e-01, -6.9547e-03],\n",
            "        [ 3.8805e-02, -1.0902e-01,  6.4091e-02, -5.3531e-02,  3.5178e-02,\n",
            "         -5.3214e-02,  1.0000e-01,  4.1095e-02, -1.3970e-01, -3.4703e-02],\n",
            "        [-1.5839e-02, -2.0819e-01,  2.0836e-02, -9.3387e-02,  4.7888e-02,\n",
            "         -1.8562e-01,  9.2416e-02,  1.0916e-01, -2.6192e-01,  4.0612e-02],\n",
            "        [-6.2519e-03, -1.2708e-01,  9.4624e-02, -6.9932e-02,  1.3622e-02,\n",
            "         -1.0370e-01,  1.5753e-02,  4.0857e-02, -1.9728e-01, -2.6777e-02],\n",
            "        [-6.4330e-02, -2.0312e-01,  3.5923e-02, -3.9812e-02,  3.9184e-02,\n",
            "         -8.9933e-02,  6.9117e-02, -1.3312e-02, -2.0792e-01, -4.5243e-02],\n",
            "        [-8.5539e-04, -9.7697e-02,  3.2182e-02, -6.0325e-02,  5.7753e-02,\n",
            "         -1.2442e-01,  8.1255e-02, -4.8669e-02, -1.6857e-01, -2.6464e-02],\n",
            "        [-9.8315e-02, -2.9621e-01,  4.5625e-02, -4.6868e-02,  1.2252e-02,\n",
            "         -2.6155e-01,  7.6243e-02, -1.9706e-02, -2.6576e-01,  1.5019e-02],\n",
            "        [-1.2675e-01, -3.0959e-01,  6.4017e-02, -5.3224e-02,  6.9897e-03,\n",
            "         -2.2059e-01,  4.8655e-02,  4.0208e-02, -2.8347e-01, -4.5063e-02],\n",
            "        [-1.4714e-02, -1.6212e-01,  4.7331e-02, -4.1907e-02, -1.2059e-02,\n",
            "         -1.2647e-01,  7.5108e-02,  3.7218e-02, -2.3778e-01,  2.5379e-03],\n",
            "        [-7.9403e-03, -1.6072e-01,  7.0115e-02, -4.9390e-02,  1.2686e-02,\n",
            "         -1.9396e-01,  3.4167e-02,  4.0843e-02, -1.7017e-01, -3.7908e-02],\n",
            "        [-2.6991e-02, -1.2562e-01,  6.5730e-02, -1.0763e-01,  1.1012e-02,\n",
            "         -1.7419e-01,  4.3910e-02,  1.0563e-02, -2.2215e-01,  1.0964e-04],\n",
            "        [ 3.7648e-02, -3.5847e-02,  1.1637e-01, -6.6862e-02,  5.4292e-02,\n",
            "         -9.7421e-02,  4.0061e-02,  4.2649e-02, -1.0469e-01, -4.1696e-02],\n",
            "        [-8.1678e-02, -2.0580e-01,  4.3714e-02, -7.0794e-02,  7.6751e-03,\n",
            "         -1.0973e-01,  2.8932e-02,  4.4931e-02, -2.0293e-01, -4.5378e-02],\n",
            "        [-2.8775e-02, -1.5230e-01,  5.5339e-03, -1.2967e-01, -1.0177e-02,\n",
            "         -1.7773e-01,  9.4726e-03,  4.7084e-02, -2.2320e-01, -6.4484e-02],\n",
            "        [ 1.8312e-02, -1.6170e-01,  9.4698e-03, -5.8093e-02, -1.8069e-02,\n",
            "         -1.2704e-01,  6.2940e-02, -2.9544e-02, -2.2619e-01, -4.7146e-03],\n",
            "        [-7.2446e-02, -1.8102e-01,  1.0087e-01, -5.4972e-02,  4.1972e-02,\n",
            "         -1.4342e-01,  2.3067e-02,  4.4141e-02, -2.3654e-01, -7.5780e-03],\n",
            "        [-7.1214e-02, -2.4391e-01,  5.1246e-02, -4.9074e-02,  4.5194e-02,\n",
            "         -1.7111e-01,  1.3715e-01, -2.2469e-02, -1.7490e-01, -6.1037e-02],\n",
            "        [-1.2751e-01, -1.7062e-01,  7.1175e-02, -5.1518e-02, -3.6096e-03,\n",
            "         -1.2815e-01,  4.5244e-02,  4.1762e-02, -2.3113e-01, -5.5459e-02],\n",
            "        [-1.1039e-02, -1.7036e-01,  1.1533e-01, -7.8024e-02,  3.3422e-02,\n",
            "         -1.1543e-01,  3.7156e-02, -3.9033e-03, -1.7697e-01,  3.1662e-03],\n",
            "        [-4.9788e-02, -2.2804e-01,  4.1948e-02, -8.0487e-02,  2.1836e-02,\n",
            "         -1.0340e-01,  4.8232e-02, -3.0893e-02, -2.3527e-01,  7.2819e-02],\n",
            "        [-1.3556e-01, -1.8644e-01,  5.5491e-02, -5.4687e-02, -1.0147e-02,\n",
            "         -1.1696e-01,  2.6426e-02,  3.6281e-02, -2.6013e-01, -8.6251e-02],\n",
            "        [-7.6828e-02, -2.3511e-01,  5.7058e-02, -8.7094e-02,  2.5289e-02,\n",
            "         -1.1284e-01,  3.1177e-02,  3.4595e-02, -1.8008e-01, -6.1271e-02],\n",
            "        [-1.3031e-01, -2.0699e-01,  6.2965e-02, -5.7936e-02,  7.8177e-03,\n",
            "         -1.4494e-01,  3.6688e-02,  4.7560e-02, -2.2953e-01, -8.7819e-02],\n",
            "        [-7.5216e-03, -1.2506e-01,  3.6685e-02, -9.6947e-02, -6.3674e-03,\n",
            "         -1.4444e-01,  7.7377e-02, -3.2059e-02, -1.7506e-01, -4.7242e-02],\n",
            "        [ 1.0074e-02, -1.5076e-01, -2.3941e-03, -5.5382e-02, -3.0818e-02,\n",
            "         -1.3248e-01,  9.5581e-02, -2.4349e-02, -2.2210e-01,  3.0727e-03],\n",
            "        [-4.5261e-02, -1.5530e-01, -4.1584e-02, -1.1121e-01, -1.9373e-02,\n",
            "         -1.0376e-01,  1.0129e-01,  7.2553e-02, -2.5334e-01, -4.2948e-02],\n",
            "        [ 3.4874e-03, -1.5640e-01,  3.3107e-02, -8.9392e-02, -1.1451e-03,\n",
            "         -1.1504e-01,  6.5493e-02,  1.7216e-02, -1.7520e-01, -5.4223e-02],\n",
            "        [-1.2320e-03, -1.5037e-01, -4.1784e-02, -9.2709e-02,  1.7387e-02,\n",
            "         -8.5278e-02,  4.1931e-02, -4.4820e-02, -2.4288e-01, -4.5380e-02],\n",
            "        [-9.0283e-02, -1.1965e-01,  4.0868e-02, -6.1721e-02, -2.0059e-02,\n",
            "         -9.1501e-02,  5.4839e-02,  2.1016e-02, -2.0791e-01, -4.4225e-02],\n",
            "        [ 2.5963e-02, -1.5364e-01,  4.9933e-03, -4.0574e-02,  3.7185e-02,\n",
            "         -8.2416e-02,  1.2666e-01, -5.2119e-03, -1.4758e-01, -1.9317e-02],\n",
            "        [-5.7747e-02, -8.9435e-02,  1.5214e-02, -1.0525e-01, -6.5416e-03,\n",
            "         -1.5071e-01,  4.3761e-02,  4.3552e-02, -2.1085e-01, -8.3312e-02],\n",
            "        [-9.3728e-02, -1.4023e-01,  2.8774e-02, -8.6115e-02, -5.5623e-04,\n",
            "         -9.7661e-02,  2.6087e-02,  5.3785e-02, -2.0856e-01, -4.4571e-02],\n",
            "        [-5.1138e-02, -9.7855e-02, -5.0187e-02, -9.2949e-02,  5.7224e-03,\n",
            "         -1.8594e-01,  5.6163e-02,  1.0148e-02, -2.1175e-01, -4.0122e-02],\n",
            "        [-5.5525e-02, -3.3306e-01,  1.3216e-01, -1.8304e-02,  7.4696e-03,\n",
            "         -1.6571e-01,  4.4093e-02,  3.8707e-02, -2.2259e-01, -4.4693e-02],\n",
            "        [ 2.6529e-02, -6.6183e-02,  5.0549e-02, -1.4722e-02,  2.4663e-02,\n",
            "         -1.0713e-01,  9.1494e-02,  2.6978e-02, -7.0947e-02, -5.0620e-03],\n",
            "        [-4.5486e-03, -2.4462e-01,  3.8090e-02, -7.1918e-02, -2.3900e-02,\n",
            "         -1.7079e-01,  4.0086e-02,  3.6513e-02, -1.8881e-01, -1.4620e-02],\n",
            "        [-9.6333e-02, -1.9340e-01,  7.3486e-02, -6.5638e-02,  1.5049e-02,\n",
            "         -1.5217e-01,  4.3093e-02,  5.2968e-02, -2.1067e-01, -4.7088e-02],\n",
            "        [-2.4311e-02, -2.3827e-01,  1.9599e-02, -6.0177e-02,  4.2551e-02,\n",
            "         -2.7543e-01,  3.4945e-02, -1.1060e-02, -2.2314e-01, -9.0123e-03],\n",
            "        [-1.4764e-02, -1.2859e-01,  8.5574e-02, -7.3194e-02,  2.8378e-02,\n",
            "         -1.3227e-01,  6.4861e-02,  8.2158e-02, -1.6366e-01, -4.0176e-02],\n",
            "        [-7.7838e-03, -1.2963e-01,  6.5762e-02, -9.4860e-02,  2.6968e-02,\n",
            "         -3.1117e-02,  3.6262e-02, -2.3622e-02, -1.8512e-01, -6.6984e-02],\n",
            "        [-1.2838e-01, -1.7682e-01,  8.0266e-03, -7.3129e-02,  1.7264e-02,\n",
            "         -2.0603e-01,  1.7578e-02,  7.9829e-02, -2.4368e-01, -9.2973e-03],\n",
            "        [-1.2799e-01, -1.7729e-01,  5.6510e-02, -6.7355e-02, -1.5913e-02,\n",
            "         -1.3190e-01,  3.9669e-02,  6.9716e-02, -2.3290e-01, -9.0237e-02],\n",
            "        [-4.2415e-02, -7.1398e-02,  1.2513e-01, -6.5009e-02,  5.8201e-02,\n",
            "         -1.0671e-01,  3.2949e-02,  4.3688e-02, -1.9461e-01, -2.7783e-02],\n",
            "        [-9.6970e-02, -2.5470e-01,  6.4332e-02, -6.4285e-02,  5.2083e-02,\n",
            "         -1.7038e-01,  3.5488e-02,  6.1743e-02, -2.4941e-01, -6.0794e-02],\n",
            "        [-1.8087e-02, -1.4536e-01,  1.4975e-02, -8.7110e-02,  9.6449e-03,\n",
            "         -1.1782e-01,  1.4995e-01,  5.8003e-02, -1.1922e-01,  3.0737e-02],\n",
            "        [ 3.8096e-02, -1.6433e-01,  1.1513e-02, -8.2458e-02, -7.0574e-02,\n",
            "         -1.3498e-01,  2.1483e-01, -1.7494e-02, -1.3704e-01, -1.1581e-01],\n",
            "        [-2.5143e-02, -2.1151e-01,  1.3634e-01, -1.2557e-01,  6.1492e-02,\n",
            "         -9.6713e-02,  5.1545e-02, -7.6224e-03, -1.9338e-01,  9.3100e-03],\n",
            "        [-4.5819e-02, -1.8043e-01,  1.0675e-01, -1.0035e-01,  5.9834e-02,\n",
            "         -1.6687e-01,  5.4685e-02, -6.3031e-03, -1.5874e-01, -1.3680e-04],\n",
            "        [-5.0357e-02, -2.6480e-01,  5.6411e-02, -3.2437e-02,  4.5826e-02,\n",
            "         -2.3643e-01,  8.1602e-02, -7.5070e-03, -2.3249e-01, -2.0080e-02],\n",
            "        [-3.8261e-02, -1.9121e-01,  3.8639e-02, -4.1754e-02, -8.8177e-03,\n",
            "         -1.3479e-01,  8.5335e-02,  2.7684e-02, -2.8447e-01, -3.4417e-02]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zv31Es4e52_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "            labels = Variable(labels)\n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Predication\n",
        "        print(outputs)\n",
        "        print(outputs.shape)\n",
        "       \n",
        "        out = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        ls1 = criterion(outputs, labels)\n",
        "        ls2 = criterion(outputs, labels)\n",
        "\n",
        "        #total loss\n",
        "        loss = ls1 + ls2\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.cuda())\n",
        "                else:\n",
        "                    images = Variable(images)\n",
        "                \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}